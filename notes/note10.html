<p>Although it might sound like a long time ago, the Tesla architecture marked a pivotal moment in GPU development, shaping the GPUs we use today.</p>

<p>ğŸ”¥ The main breakthrough: the introduction of the <strong>ğ—šğ—²ğ—»ğ—²ğ—¿ğ—¶ğ—° ğ—¦ğ˜ğ—¿ğ—²ğ—®ğ—ºğ—¶ğ—»ğ—´ ğ— ğ˜‚ğ—¹ğ˜ğ—¶ğ—½ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¼ğ—¿ (ğ—¦ğ— )</strong>, capable of performing any type of work â€” not just graphics commands, like older GPUs. With the help of their new SM design Nvidia GPUs allowed programmers to use the GPU more as a general-purpose processor, moving beyond the traditional graphics concepts.</p>

<p>ğŸŒŸ At the same time, NVIDIA introduced CUDA, their programming language designed for NVIDIA GPUs. With the release of CUDA & the Streaming Multiprocessor, NVIDIA aimed to make <strong>ğ—šğ—£ğ—¨ ğ—½ğ—¿ğ—¼ğ—´ğ—¿ğ—®ğ—ºğ—ºğ—¶ğ—»ğ—´ ğ—®ğ—°ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—¯ğ—¹ğ—² ğ˜ğ—¼ ğ—®ğ—¹ğ—¹ ğ—±ğ—²ğ˜ƒğ—²ğ—¹ğ—¼ğ—½ğ—²ğ—¿ğ˜€</strong>â€”not just graphics experts.</p>

<p>âš ï¸ Itâ€™s important to understand Tesla because everything that followed has been an evolution in the same direction: making GPUs increasingly powerful general-purpose processors.</p>

<h3>âš™ï¸ NVIDIA Tesla in numbers:</h3>
<ul>
<li>TPCs / SMs: 8 TPCs Ã— 2 SMs â†’ 16 SMs</li>
<li>Warps / Threads: 24 warps/SM â†’ 384 warps, 768 threads/SM â†’ 12,288 threads total</li>
<li>Execution Units: 8 SPs + 2 SFUs per SM â†’ 128 SPs + 32 SFUs total</li>
<li>Peak Compute: 36 GFLOPs/SM â†’ ~576 GFLOPs chip-wide</li>
<li>Shared Memory: 16 KB/SM â†’ 256 KB total</li>
<li>L2 Cache: small, shared across SMs and ROPs</li>
<li>Global Memory: 768 MB GDDR3</li>
</ul>